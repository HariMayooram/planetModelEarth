{
  "version": 3,
  "sources": ["../../@langchain/core/dist/utils/types/is_zod_schema.js", "../../@langchain/core/dist/language_models/chat_models.js"],
  "sourcesContent": ["/**\n * Given either a Zod schema, or plain object, determine if the input is a Zod schema.\n *\n * @param {z.ZodType<RunOutput> | Record<string, any>} input\n * @returns {boolean} Whether or not the provided input is a Zod schema.\n */\nexport function isZodSchema(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\ninput) {\n    // Check for a characteristic method of Zod schemas\n    return typeof input?.parse === \"function\";\n}\n", "import { zodToJsonSchema } from \"zod-to-json-schema\";\nimport { AIMessage, HumanMessage, coerceMessageLikeToMessage, isAIMessageChunk, isBaseMessage, isAIMessage, } from \"../messages/index.js\";\nimport { RUN_KEY, } from \"../outputs.js\";\nimport { BaseLanguageModel, } from \"./base.js\";\nimport { CallbackManager, } from \"../callbacks/manager.js\";\nimport { RunnableLambda, RunnableSequence, } from \"../runnables/base.js\";\nimport { concat } from \"../utils/stream.js\";\nimport { RunnablePassthrough } from \"../runnables/passthrough.js\";\nimport { isZodSchema } from \"../utils/types/is_zod_schema.js\";\nimport { callbackHandlerPrefersStreaming } from \"../callbacks/base.js\";\n/**\n * Creates a transform stream for encoding chat message chunks.\n * @deprecated Use {@link BytesOutputParser} instead\n * @returns A TransformStream instance that encodes chat message chunks.\n */\nexport function createChatMessageChunkEncoderStream() {\n    const textEncoder = new TextEncoder();\n    return new TransformStream({\n        transform(chunk, controller) {\n            controller.enqueue(textEncoder.encode(typeof chunk.content === \"string\"\n                ? chunk.content\n                : JSON.stringify(chunk.content)));\n        },\n    });\n}\n/**\n * Base class for chat models. It extends the BaseLanguageModel class and\n * provides methods for generating chat based on input messages.\n */\nexport class BaseChatModel extends BaseLanguageModel {\n    constructor(fields) {\n        super(fields);\n        // Only ever instantiated in main LangChain\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"chat_models\", this._llmType()]\n        });\n        Object.defineProperty(this, \"disableStreaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n    }\n    _separateRunnableConfigFromCallOptionsCompat(options) {\n        // For backwards compat, keep `signal` in both runnableConfig and callOptions\n        const [runnableConfig, callOptions] = super._separateRunnableConfigFromCallOptions(options);\n        callOptions.signal = runnableConfig.signal;\n        return [runnableConfig, callOptions];\n    }\n    /**\n     * Invokes the chat model with a single input.\n     * @param input The input for the language model.\n     * @param options The call options.\n     * @returns A Promise that resolves to a BaseMessageChunk.\n     */\n    async invoke(input, options) {\n        const promptValue = BaseChatModel._convertInputToPromptValue(input);\n        const result = await this.generatePrompt([promptValue], options, options?.callbacks);\n        const chatGeneration = result.generations[0][0];\n        // TODO: Remove cast after figuring out inheritance\n        return chatGeneration.message;\n    }\n    // eslint-disable-next-line require-yield\n    async *_streamResponseChunks(_messages, _options, _runManager) {\n        throw new Error(\"Not implemented.\");\n    }\n    async *_streamIterator(input, options) {\n        // Subclass check required to avoid double callbacks with default implementation\n        if (this._streamResponseChunks ===\n            BaseChatModel.prototype._streamResponseChunks ||\n            this.disableStreaming) {\n            yield this.invoke(input, options);\n        }\n        else {\n            const prompt = BaseChatModel._convertInputToPromptValue(input);\n            const messages = prompt.toChatMessages();\n            const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(options);\n            const inheritableMetadata = {\n                ...runnableConfig.metadata,\n                ...this.getLsParams(callOptions),\n            };\n            const callbackManager_ = await CallbackManager.configure(runnableConfig.callbacks, this.callbacks, runnableConfig.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });\n            const extra = {\n                options: callOptions,\n                invocation_params: this?.invocationParams(callOptions),\n                batch_size: 1,\n            };\n            const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), [messages], runnableConfig.runId, undefined, extra, undefined, undefined, runnableConfig.runName);\n            let generationChunk;\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            let llmOutput;\n            try {\n                for await (const chunk of this._streamResponseChunks(messages, callOptions, runManagers?.[0])) {\n                    if (chunk.message.id == null) {\n                        const runId = runManagers?.at(0)?.runId;\n                        if (runId != null)\n                            chunk.message._updateId(`run-${runId}`);\n                    }\n                    chunk.message.response_metadata = {\n                        ...chunk.generationInfo,\n                        ...chunk.message.response_metadata,\n                    };\n                    yield chunk.message;\n                    if (!generationChunk) {\n                        generationChunk = chunk;\n                    }\n                    else {\n                        generationChunk = generationChunk.concat(chunk);\n                    }\n                    if (isAIMessageChunk(chunk.message) &&\n                        chunk.message.usage_metadata !== undefined) {\n                        llmOutput = {\n                            tokenUsage: {\n                                promptTokens: chunk.message.usage_metadata.input_tokens,\n                                completionTokens: chunk.message.usage_metadata.output_tokens,\n                                totalTokens: chunk.message.usage_metadata.total_tokens,\n                            },\n                        };\n                    }\n                }\n            }\n            catch (err) {\n                await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMError(err)));\n                throw err;\n            }\n            await Promise.all((runManagers ?? []).map((runManager) => runManager?.handleLLMEnd({\n                // TODO: Remove cast after figuring out inheritance\n                generations: [[generationChunk]],\n                llmOutput,\n            })));\n        }\n    }\n    getLsParams(options) {\n        const providerName = this.getName().startsWith(\"Chat\")\n            ? this.getName().replace(\"Chat\", \"\")\n            : this.getName();\n        return {\n            ls_model_type: \"chat\",\n            ls_stop: options.stop,\n            ls_provider: providerName,\n        };\n    }\n    /** @ignore */\n    async _generateUncached(messages, parsedOptions, handledOptions, startedRunManagers) {\n        const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));\n        let runManagers;\n        if (startedRunManagers !== undefined &&\n            startedRunManagers.length === baseMessages.length) {\n            runManagers = startedRunManagers;\n        }\n        else {\n            const inheritableMetadata = {\n                ...handledOptions.metadata,\n                ...this.getLsParams(parsedOptions),\n            };\n            // create callback manager and start run\n            const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });\n            const extra = {\n                options: parsedOptions,\n                invocation_params: this?.invocationParams(parsedOptions),\n                batch_size: 1,\n            };\n            runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages, handledOptions.runId, undefined, extra, undefined, undefined, handledOptions.runName);\n        }\n        const generations = [];\n        const llmOutputs = [];\n        // Even if stream is not explicitly called, check if model is implicitly\n        // called from streamEvents() or streamLog() to get all streamed events.\n        // Bail out if _streamResponseChunks not overridden\n        const hasStreamingHandler = !!runManagers?.[0].handlers.find(callbackHandlerPrefersStreaming);\n        if (hasStreamingHandler &&\n            !this.disableStreaming &&\n            baseMessages.length === 1 &&\n            this._streamResponseChunks !==\n                BaseChatModel.prototype._streamResponseChunks) {\n            try {\n                const stream = await this._streamResponseChunks(baseMessages[0], parsedOptions, runManagers?.[0]);\n                let aggregated;\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                let llmOutput;\n                for await (const chunk of stream) {\n                    if (chunk.message.id == null) {\n                        const runId = runManagers?.at(0)?.runId;\n                        if (runId != null)\n                            chunk.message._updateId(`run-${runId}`);\n                    }\n                    if (aggregated === undefined) {\n                        aggregated = chunk;\n                    }\n                    else {\n                        aggregated = concat(aggregated, chunk);\n                    }\n                    if (isAIMessageChunk(chunk.message) &&\n                        chunk.message.usage_metadata !== undefined) {\n                        llmOutput = {\n                            tokenUsage: {\n                                promptTokens: chunk.message.usage_metadata.input_tokens,\n                                completionTokens: chunk.message.usage_metadata.output_tokens,\n                                totalTokens: chunk.message.usage_metadata.total_tokens,\n                            },\n                        };\n                    }\n                }\n                if (aggregated === undefined) {\n                    throw new Error(\"Received empty response from chat model call.\");\n                }\n                generations.push([aggregated]);\n                await runManagers?.[0].handleLLMEnd({\n                    generations,\n                    llmOutput,\n                });\n            }\n            catch (e) {\n                await runManagers?.[0].handleLLMError(e);\n                throw e;\n            }\n        }\n        else {\n            // generate results\n            const results = await Promise.allSettled(baseMessages.map((messageList, i) => this._generate(messageList, { ...parsedOptions, promptIndex: i }, runManagers?.[i])));\n            // handle results\n            await Promise.all(results.map(async (pResult, i) => {\n                if (pResult.status === \"fulfilled\") {\n                    const result = pResult.value;\n                    for (const generation of result.generations) {\n                        if (generation.message.id == null) {\n                            const runId = runManagers?.at(0)?.runId;\n                            if (runId != null)\n                                generation.message._updateId(`run-${runId}`);\n                        }\n                        generation.message.response_metadata = {\n                            ...generation.generationInfo,\n                            ...generation.message.response_metadata,\n                        };\n                    }\n                    if (result.generations.length === 1) {\n                        result.generations[0].message.response_metadata = {\n                            ...result.llmOutput,\n                            ...result.generations[0].message.response_metadata,\n                        };\n                    }\n                    generations[i] = result.generations;\n                    llmOutputs[i] = result.llmOutput;\n                    return runManagers?.[i]?.handleLLMEnd({\n                        generations: [result.generations],\n                        llmOutput: result.llmOutput,\n                    });\n                }\n                else {\n                    // status === \"rejected\"\n                    await runManagers?.[i]?.handleLLMError(pResult.reason);\n                    return Promise.reject(pResult.reason);\n                }\n            }));\n        }\n        // create combined output\n        const output = {\n            generations,\n            llmOutput: llmOutputs.length\n                ? this._combineLLMOutput?.(...llmOutputs)\n                : undefined,\n        };\n        Object.defineProperty(output, RUN_KEY, {\n            value: runManagers\n                ? { runIds: runManagers?.map((manager) => manager.runId) }\n                : undefined,\n            configurable: true,\n        });\n        return output;\n    }\n    async _generateCached({ messages, cache, llmStringKey, parsedOptions, handledOptions, }) {\n        const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));\n        const inheritableMetadata = {\n            ...handledOptions.metadata,\n            ...this.getLsParams(parsedOptions),\n        };\n        // create callback manager and start run\n        const callbackManager_ = await CallbackManager.configure(handledOptions.callbacks, this.callbacks, handledOptions.tags, this.tags, inheritableMetadata, this.metadata, { verbose: this.verbose });\n        const extra = {\n            options: parsedOptions,\n            invocation_params: this?.invocationParams(parsedOptions),\n            batch_size: 1,\n        };\n        const runManagers = await callbackManager_?.handleChatModelStart(this.toJSON(), baseMessages, handledOptions.runId, undefined, extra, undefined, undefined, handledOptions.runName);\n        // generate results\n        const missingPromptIndices = [];\n        const results = await Promise.allSettled(baseMessages.map(async (baseMessage, index) => {\n            // Join all content into one string for the prompt index\n            const prompt = BaseChatModel._convertInputToPromptValue(baseMessage).toString();\n            const result = await cache.lookup(prompt, llmStringKey);\n            if (result == null) {\n                missingPromptIndices.push(index);\n            }\n            return result;\n        }));\n        // Map run managers to the results before filtering out null results\n        // Null results are just absent from the cache.\n        const cachedResults = results\n            .map((result, index) => ({ result, runManager: runManagers?.[index] }))\n            .filter(({ result }) => (result.status === \"fulfilled\" && result.value != null) ||\n            result.status === \"rejected\");\n        // Handle results and call run managers\n        const generations = [];\n        await Promise.all(cachedResults.map(async ({ result: promiseResult, runManager }, i) => {\n            if (promiseResult.status === \"fulfilled\") {\n                const result = promiseResult.value;\n                generations[i] = result.map((result) => {\n                    if (\"message\" in result &&\n                        isBaseMessage(result.message) &&\n                        isAIMessage(result.message)) {\n                        // eslint-disable-next-line no-param-reassign\n                        result.message.usage_metadata = {\n                            input_tokens: 0,\n                            output_tokens: 0,\n                            total_tokens: 0,\n                        };\n                    }\n                    // eslint-disable-next-line no-param-reassign\n                    result.generationInfo = {\n                        ...result.generationInfo,\n                        tokenUsage: {},\n                    };\n                    return result;\n                });\n                if (result.length) {\n                    await runManager?.handleLLMNewToken(result[0].text);\n                }\n                return runManager?.handleLLMEnd({\n                    generations: [result],\n                }, undefined, undefined, undefined, {\n                    cached: true,\n                });\n            }\n            else {\n                // status === \"rejected\"\n                await runManager?.handleLLMError(promiseResult.reason, undefined, undefined, undefined, {\n                    cached: true,\n                });\n                return Promise.reject(promiseResult.reason);\n            }\n        }));\n        const output = {\n            generations,\n            missingPromptIndices,\n            startedRunManagers: runManagers,\n        };\n        // This defines RUN_KEY as a non-enumerable property on the output object\n        // so that it is not serialized when the output is stringified, and so that\n        // it isnt included when listing the keys of the output object.\n        Object.defineProperty(output, RUN_KEY, {\n            value: runManagers\n                ? { runIds: runManagers?.map((manager) => manager.runId) }\n                : undefined,\n            configurable: true,\n        });\n        return output;\n    }\n    /**\n     * Generates chat based on the input messages.\n     * @param messages An array of arrays of BaseMessage instances.\n     * @param options The call options or an array of stop sequences.\n     * @param callbacks The callbacks for the language model.\n     * @returns A Promise that resolves to an LLMResult.\n     */\n    async generate(messages, options, callbacks) {\n        // parse call options\n        let parsedOptions;\n        if (Array.isArray(options)) {\n            parsedOptions = { stop: options };\n        }\n        else {\n            parsedOptions = options;\n        }\n        const baseMessages = messages.map((messageList) => messageList.map(coerceMessageLikeToMessage));\n        const [runnableConfig, callOptions] = this._separateRunnableConfigFromCallOptionsCompat(parsedOptions);\n        runnableConfig.callbacks = runnableConfig.callbacks ?? callbacks;\n        if (!this.cache) {\n            return this._generateUncached(baseMessages, callOptions, runnableConfig);\n        }\n        const { cache } = this;\n        const llmStringKey = this._getSerializedCacheKeyParametersForCall(callOptions);\n        const { generations, missingPromptIndices, startedRunManagers } = await this._generateCached({\n            messages: baseMessages,\n            cache,\n            llmStringKey,\n            parsedOptions: callOptions,\n            handledOptions: runnableConfig,\n        });\n        let llmOutput = {};\n        if (missingPromptIndices.length > 0) {\n            const results = await this._generateUncached(missingPromptIndices.map((i) => baseMessages[i]), callOptions, runnableConfig, startedRunManagers !== undefined\n                ? missingPromptIndices.map((i) => startedRunManagers?.[i])\n                : undefined);\n            await Promise.all(results.generations.map(async (generation, index) => {\n                const promptIndex = missingPromptIndices[index];\n                generations[promptIndex] = generation;\n                // Join all content into one string for the prompt index\n                const prompt = BaseChatModel._convertInputToPromptValue(baseMessages[promptIndex]).toString();\n                return cache.update(prompt, llmStringKey, generation);\n            }));\n            llmOutput = results.llmOutput ?? {};\n        }\n        return { generations, llmOutput };\n    }\n    /**\n     * Get the parameters used to invoke the model\n     */\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    invocationParams(_options) {\n        return {};\n    }\n    _modelType() {\n        return \"base_chat_model\";\n    }\n    /**\n     * @deprecated\n     * Return a json-like object representing this LLM.\n     */\n    serialize() {\n        return {\n            ...this.invocationParams(),\n            _type: this._llmType(),\n            _model: this._modelType(),\n        };\n    }\n    /**\n     * Generates a prompt based on the input prompt values.\n     * @param promptValues An array of BasePromptValue instances.\n     * @param options The call options or an array of stop sequences.\n     * @param callbacks The callbacks for the language model.\n     * @returns A Promise that resolves to an LLMResult.\n     */\n    async generatePrompt(promptValues, options, callbacks) {\n        const promptMessages = promptValues.map((promptValue) => promptValue.toChatMessages());\n        return this.generate(promptMessages, options, callbacks);\n    }\n    /**\n     * @deprecated Use .invoke() instead. Will be removed in 0.2.0.\n     *\n     * Makes a single call to the chat model.\n     * @param messages An array of BaseMessage instances.\n     * @param options The call options or an array of stop sequences.\n     * @param callbacks The callbacks for the language model.\n     * @returns A Promise that resolves to a BaseMessage.\n     */\n    async call(messages, options, callbacks) {\n        const result = await this.generate([messages.map(coerceMessageLikeToMessage)], options, callbacks);\n        const generations = result.generations;\n        return generations[0][0].message;\n    }\n    /**\n     * @deprecated Use .invoke() instead. Will be removed in 0.2.0.\n     *\n     * Makes a single call to the chat model with a prompt value.\n     * @param promptValue The value of the prompt.\n     * @param options The call options or an array of stop sequences.\n     * @param callbacks The callbacks for the language model.\n     * @returns A Promise that resolves to a BaseMessage.\n     */\n    async callPrompt(promptValue, options, callbacks) {\n        const promptMessages = promptValue.toChatMessages();\n        return this.call(promptMessages, options, callbacks);\n    }\n    /**\n     * @deprecated Use .invoke() instead. Will be removed in 0.2.0.\n     *\n     * Predicts the next message based on the input messages.\n     * @param messages An array of BaseMessage instances.\n     * @param options The call options or an array of stop sequences.\n     * @param callbacks The callbacks for the language model.\n     * @returns A Promise that resolves to a BaseMessage.\n     */\n    async predictMessages(messages, options, callbacks) {\n        return this.call(messages, options, callbacks);\n    }\n    /**\n     * @deprecated Use .invoke() instead. Will be removed in 0.2.0.\n     *\n     * Predicts the next message based on a text input.\n     * @param text The text input.\n     * @param options The call options or an array of stop sequences.\n     * @param callbacks The callbacks for the language model.\n     * @returns A Promise that resolves to a string.\n     */\n    async predict(text, options, callbacks) {\n        const message = new HumanMessage(text);\n        const result = await this.call([message], options, callbacks);\n        if (typeof result.content !== \"string\") {\n            throw new Error(\"Cannot use predict when output is not a string.\");\n        }\n        return result.content;\n    }\n    withStructuredOutput(outputSchema, config) {\n        if (typeof this.bindTools !== \"function\") {\n            throw new Error(`Chat model must implement \".bindTools()\" to use withStructuredOutput.`);\n        }\n        if (config?.strict) {\n            throw new Error(`\"strict\" mode is not supported for this model by default.`);\n        }\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const schema = outputSchema;\n        const name = config?.name;\n        const description = schema.description ?? \"A function available to call.\";\n        const method = config?.method;\n        const includeRaw = config?.includeRaw;\n        if (method === \"jsonMode\") {\n            throw new Error(`Base withStructuredOutput implementation only supports \"functionCalling\" as a method.`);\n        }\n        let functionName = name ?? \"extract\";\n        let tools;\n        if (isZodSchema(schema)) {\n            tools = [\n                {\n                    type: \"function\",\n                    function: {\n                        name: functionName,\n                        description,\n                        parameters: zodToJsonSchema(schema),\n                    },\n                },\n            ];\n        }\n        else {\n            if (\"name\" in schema) {\n                functionName = schema.name;\n            }\n            tools = [\n                {\n                    type: \"function\",\n                    function: {\n                        name: functionName,\n                        description,\n                        parameters: schema,\n                    },\n                },\n            ];\n        }\n        const llm = this.bindTools(tools);\n        const outputParser = RunnableLambda.from((input) => {\n            if (!input.tool_calls || input.tool_calls.length === 0) {\n                throw new Error(\"No tool calls found in the response.\");\n            }\n            const toolCall = input.tool_calls.find((tc) => tc.name === functionName);\n            if (!toolCall) {\n                throw new Error(`No tool call found with name ${functionName}.`);\n            }\n            return toolCall.args;\n        });\n        if (!includeRaw) {\n            return llm.pipe(outputParser).withConfig({\n                runName: \"StructuredOutput\",\n            });\n        }\n        const parserAssign = RunnablePassthrough.assign({\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            parsed: (input, config) => outputParser.invoke(input.raw, config),\n        });\n        const parserNone = RunnablePassthrough.assign({\n            parsed: () => null,\n        });\n        const parsedWithFallback = parserAssign.withFallbacks({\n            fallbacks: [parserNone],\n        });\n        return RunnableSequence.from([\n            {\n                raw: llm,\n            },\n            parsedWithFallback,\n        ]).withConfig({\n            runName: \"StructuredOutputRunnable\",\n        });\n    }\n}\n/**\n * An abstract class that extends BaseChatModel and provides a simple\n * implementation of _generate.\n */\nexport class SimpleChatModel extends BaseChatModel {\n    async _generate(messages, options, runManager) {\n        const text = await this._call(messages, options, runManager);\n        const message = new AIMessage(text);\n        if (typeof message.content !== \"string\") {\n            throw new Error(\"Cannot generate with a simple chat model when output is not a string.\");\n        }\n        return {\n            generations: [\n                {\n                    text: message.content,\n                    message,\n                },\n            ],\n        };\n    }\n}\n"],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;AAMO,SAAS,YAEhB,OAAO;AAEH,SAAO,QAAO,+BAAO,WAAU;AACnC;;;ACkBO,IAAM,gBAAN,MAAM,uBAAsB,kBAAkB;AAAA,EACjD,YAAY,QAAQ;AAChB,UAAM,MAAM;AAEZ,WAAO,eAAe,MAAM,gBAAgB;AAAA,MACxC,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO,CAAC,aAAa,eAAe,KAAK,SAAS,CAAC;AAAA,IACvD,CAAC;AACD,WAAO,eAAe,MAAM,oBAAoB;AAAA,MAC5C,YAAY;AAAA,MACZ,cAAc;AAAA,MACd,UAAU;AAAA,MACV,OAAO;AAAA,IACX,CAAC;AAAA,EACL;AAAA,EACA,6CAA6C,SAAS;AAElD,UAAM,CAAC,gBAAgB,WAAW,IAAI,MAAM,uCAAuC,OAAO;AAC1F,gBAAY,SAAS,eAAe;AACpC,WAAO,CAAC,gBAAgB,WAAW;AAAA,EACvC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAOA,MAAM,OAAO,OAAO,SAAS;AACzB,UAAM,cAAc,eAAc,2BAA2B,KAAK;AAClE,UAAM,SAAS,MAAM,KAAK,eAAe,CAAC,WAAW,GAAG,SAAS,mCAAS,SAAS;AACnF,UAAM,iBAAiB,OAAO,YAAY,CAAC,EAAE,CAAC;AAE9C,WAAO,eAAe;AAAA,EAC1B;AAAA;AAAA,EAEA,OAAO,sBAAsB,WAAW,UAAU,aAAa;AAC3D,UAAM,IAAI,MAAM,kBAAkB;AAAA,EACtC;AAAA,EACA,OAAO,gBAAgB,OAAO,SAAS;AArE3C;AAuEQ,QAAI,KAAK,0BACL,eAAc,UAAU,yBACxB,KAAK,kBAAkB;AACvB,YAAM,KAAK,OAAO,OAAO,OAAO;AAAA,IACpC,OACK;AACD,YAAM,SAAS,eAAc,2BAA2B,KAAK;AAC7D,YAAM,WAAW,OAAO,eAAe;AACvC,YAAM,CAAC,gBAAgB,WAAW,IAAI,KAAK,6CAA6C,OAAO;AAC/F,YAAM,sBAAsB;AAAA,QACxB,GAAG,eAAe;AAAA,QAClB,GAAG,KAAK,YAAY,WAAW;AAAA,MACnC;AACA,YAAM,mBAAmB,MAAM,gBAAgB,UAAU,eAAe,WAAW,KAAK,WAAW,eAAe,MAAM,KAAK,MAAM,qBAAqB,KAAK,UAAU,EAAE,SAAS,KAAK,QAAQ,CAAC;AAChM,YAAM,QAAQ;AAAA,QACV,SAAS;AAAA,QACT,mBAAmB,6BAAM,iBAAiB;AAAA,QAC1C,YAAY;AAAA,MAChB;AACA,YAAM,cAAc,OAAM,qDAAkB,qBAAqB,KAAK,OAAO,GAAG,CAAC,QAAQ,GAAG,eAAe,OAAO,QAAW,OAAO,QAAW,QAAW,eAAe;AACzK,UAAI;AAEJ,UAAI;AACJ,UAAI;AACA,yBAAiB,SAAS,KAAK,sBAAsB,UAAU,aAAa,2CAAc,EAAE,GAAG;AAC3F,cAAI,MAAM,QAAQ,MAAM,MAAM;AAC1B,kBAAM,SAAQ,gDAAa,GAAG,OAAhB,mBAAoB;AAClC,gBAAI,SAAS;AACT,oBAAM,QAAQ,UAAU,OAAO,KAAK,EAAE;AAAA,UAC9C;AACA,gBAAM,QAAQ,oBAAoB;AAAA,YAC9B,GAAG,MAAM;AAAA,YACT,GAAG,MAAM,QAAQ;AAAA,UACrB;AACA,gBAAM,MAAM;AACZ,cAAI,CAAC,iBAAiB;AAClB,8BAAkB;AAAA,UACtB,OACK;AACD,8BAAkB,gBAAgB,OAAO,KAAK;AAAA,UAClD;AACA,cAAI,iBAAiB,MAAM,OAAO,KAC9B,MAAM,QAAQ,mBAAmB,QAAW;AAC5C,wBAAY;AAAA,cACR,YAAY;AAAA,gBACR,cAAc,MAAM,QAAQ,eAAe;AAAA,gBAC3C,kBAAkB,MAAM,QAAQ,eAAe;AAAA,gBAC/C,aAAa,MAAM,QAAQ,eAAe;AAAA,cAC9C;AAAA,YACJ;AAAA,UACJ;AAAA,QACJ;AAAA,MACJ,SACO,KAAK;AACR,cAAM,QAAQ,KAAK,eAAe,CAAC,GAAG,IAAI,CAAC,eAAe,yCAAY,eAAe,IAAI,CAAC;AAC1F,cAAM;AAAA,MACV;AACA,YAAM,QAAQ,KAAK,eAAe,CAAC,GAAG,IAAI,CAAC,eAAe,yCAAY,aAAa;AAAA;AAAA,QAE/E,aAAa,CAAC,CAAC,eAAe,CAAC;AAAA,QAC/B;AAAA,MACJ,EAAE,CAAC;AAAA,IACP;AAAA,EACJ;AAAA,EACA,YAAY,SAAS;AACjB,UAAM,eAAe,KAAK,QAAQ,EAAE,WAAW,MAAM,IAC/C,KAAK,QAAQ,EAAE,QAAQ,QAAQ,EAAE,IACjC,KAAK,QAAQ;AACnB,WAAO;AAAA,MACH,eAAe;AAAA,MACf,SAAS,QAAQ;AAAA,MACjB,aAAa;AAAA,IACjB;AAAA,EACJ;AAAA;AAAA,EAEA,MAAM,kBAAkB,UAAU,eAAe,gBAAgB,oBAAoB;AAlJzF;AAmJQ,UAAM,eAAe,SAAS,IAAI,CAAC,gBAAgB,YAAY,IAAI,0BAA0B,CAAC;AAC9F,QAAI;AACJ,QAAI,uBAAuB,UACvB,mBAAmB,WAAW,aAAa,QAAQ;AACnD,oBAAc;AAAA,IAClB,OACK;AACD,YAAM,sBAAsB;AAAA,QACxB,GAAG,eAAe;AAAA,QAClB,GAAG,KAAK,YAAY,aAAa;AAAA,MACrC;AAEA,YAAM,mBAAmB,MAAM,gBAAgB,UAAU,eAAe,WAAW,KAAK,WAAW,eAAe,MAAM,KAAK,MAAM,qBAAqB,KAAK,UAAU,EAAE,SAAS,KAAK,QAAQ,CAAC;AAChM,YAAM,QAAQ;AAAA,QACV,SAAS;AAAA,QACT,mBAAmB,6BAAM,iBAAiB;AAAA,QAC1C,YAAY;AAAA,MAChB;AACA,oBAAc,OAAM,qDAAkB,qBAAqB,KAAK,OAAO,GAAG,cAAc,eAAe,OAAO,QAAW,OAAO,QAAW,QAAW,eAAe;AAAA,IACzK;AACA,UAAM,cAAc,CAAC;AACrB,UAAM,aAAa,CAAC;AAIpB,UAAM,sBAAsB,CAAC,EAAC,2CAAc,GAAG,SAAS,KAAK;AAC7D,QAAI,uBACA,CAAC,KAAK,oBACN,aAAa,WAAW,KACxB,KAAK,0BACD,eAAc,UAAU,uBAAuB;AACnD,UAAI;AACA,cAAM,SAAS,MAAM,KAAK,sBAAsB,aAAa,CAAC,GAAG,eAAe,2CAAc,EAAE;AAChG,YAAI;AAEJ,YAAI;AACJ,yBAAiB,SAAS,QAAQ;AAC9B,cAAI,MAAM,QAAQ,MAAM,MAAM;AAC1B,kBAAM,SAAQ,gDAAa,GAAG,OAAhB,mBAAoB;AAClC,gBAAI,SAAS;AACT,oBAAM,QAAQ,UAAU,OAAO,KAAK,EAAE;AAAA,UAC9C;AACA,cAAI,eAAe,QAAW;AAC1B,yBAAa;AAAA,UACjB,OACK;AACD,yBAAa,OAAO,YAAY,KAAK;AAAA,UACzC;AACA,cAAI,iBAAiB,MAAM,OAAO,KAC9B,MAAM,QAAQ,mBAAmB,QAAW;AAC5C,wBAAY;AAAA,cACR,YAAY;AAAA,gBACR,cAAc,MAAM,QAAQ,eAAe;AAAA,gBAC3C,kBAAkB,MAAM,QAAQ,eAAe;AAAA,gBAC/C,aAAa,MAAM,QAAQ,eAAe;AAAA,cAC9C;AAAA,YACJ;AAAA,UACJ;AAAA,QACJ;AACA,YAAI,eAAe,QAAW;AAC1B,gBAAM,IAAI,MAAM,+CAA+C;AAAA,QACnE;AACA,oBAAY,KAAK,CAAC,UAAU,CAAC;AAC7B,eAAM,2CAAc,GAAG,aAAa;AAAA,UAChC;AAAA,UACA;AAAA,QACJ;AAAA,MACJ,SACO,GAAG;AACN,eAAM,2CAAc,GAAG,eAAe;AACtC,cAAM;AAAA,MACV;AAAA,IACJ,OACK;AAED,YAAM,UAAU,MAAM,QAAQ,WAAW,aAAa,IAAI,CAAC,aAAa,MAAM,KAAK,UAAU,aAAa,EAAE,GAAG,eAAe,aAAa,EAAE,GAAG,2CAAc,EAAE,CAAC,CAAC;AAElK,YAAM,QAAQ,IAAI,QAAQ,IAAI,OAAO,SAAS,MAAM;AAhOhE,YAAAA,KAAAC,KAAA;AAiOgB,YAAI,QAAQ,WAAW,aAAa;AAChC,gBAAM,SAAS,QAAQ;AACvB,qBAAW,cAAc,OAAO,aAAa;AACzC,gBAAI,WAAW,QAAQ,MAAM,MAAM;AAC/B,oBAAM,SAAQD,MAAA,2CAAa,GAAG,OAAhB,gBAAAA,IAAoB;AAClC,kBAAI,SAAS;AACT,2BAAW,QAAQ,UAAU,OAAO,KAAK,EAAE;AAAA,YACnD;AACA,uBAAW,QAAQ,oBAAoB;AAAA,cACnC,GAAG,WAAW;AAAA,cACd,GAAG,WAAW,QAAQ;AAAA,YAC1B;AAAA,UACJ;AACA,cAAI,OAAO,YAAY,WAAW,GAAG;AACjC,mBAAO,YAAY,CAAC,EAAE,QAAQ,oBAAoB;AAAA,cAC9C,GAAG,OAAO;AAAA,cACV,GAAG,OAAO,YAAY,CAAC,EAAE,QAAQ;AAAA,YACrC;AAAA,UACJ;AACA,sBAAY,CAAC,IAAI,OAAO;AACxB,qBAAW,CAAC,IAAI,OAAO;AACvB,kBAAOC,MAAA,2CAAc,OAAd,gBAAAA,IAAkB,aAAa;AAAA,YAClC,aAAa,CAAC,OAAO,WAAW;AAAA,YAChC,WAAW,OAAO;AAAA,UACtB;AAAA,QACJ,OACK;AAED,kBAAM,gDAAc,OAAd,mBAAkB,eAAe,QAAQ;AAC/C,iBAAO,QAAQ,OAAO,QAAQ,MAAM;AAAA,QACxC;AAAA,MACJ,CAAC,CAAC;AAAA,IACN;AAEA,UAAM,SAAS;AAAA,MACX;AAAA,MACA,WAAW,WAAW,UAChB,UAAK,sBAAL,8BAAyB,GAAG,cAC5B;AAAA,IACV;AACA,WAAO,eAAe,QAAQ,SAAS;AAAA,MACnC,OAAO,cACD,EAAE,QAAQ,2CAAa,IAAI,CAAC,YAAY,QAAQ,OAAO,IACvD;AAAA,MACN,cAAc;AAAA,IAClB,CAAC;AACD,WAAO;AAAA,EACX;AAAA,EACA,MAAM,gBAAgB,EAAE,UAAU,OAAO,cAAc,eAAe,eAAgB,GAAG;AACrF,UAAM,eAAe,SAAS,IAAI,CAAC,gBAAgB,YAAY,IAAI,0BAA0B,CAAC;AAC9F,UAAM,sBAAsB;AAAA,MACxB,GAAG,eAAe;AAAA,MAClB,GAAG,KAAK,YAAY,aAAa;AAAA,IACrC;AAEA,UAAM,mBAAmB,MAAM,gBAAgB,UAAU,eAAe,WAAW,KAAK,WAAW,eAAe,MAAM,KAAK,MAAM,qBAAqB,KAAK,UAAU,EAAE,SAAS,KAAK,QAAQ,CAAC;AAChM,UAAM,QAAQ;AAAA,MACV,SAAS;AAAA,MACT,mBAAmB,6BAAM,iBAAiB;AAAA,MAC1C,YAAY;AAAA,IAChB;AACA,UAAM,cAAc,OAAM,qDAAkB,qBAAqB,KAAK,OAAO,GAAG,cAAc,eAAe,OAAO,QAAW,OAAO,QAAW,QAAW,eAAe;AAE3K,UAAM,uBAAuB,CAAC;AAC9B,UAAM,UAAU,MAAM,QAAQ,WAAW,aAAa,IAAI,OAAO,aAAa,UAAU;AAEpF,YAAM,SAAS,eAAc,2BAA2B,WAAW,EAAE,SAAS;AAC9E,YAAM,SAAS,MAAM,MAAM,OAAO,QAAQ,YAAY;AACtD,UAAI,UAAU,MAAM;AAChB,6BAAqB,KAAK,KAAK;AAAA,MACnC;AACA,aAAO;AAAA,IACX,CAAC,CAAC;AAGF,UAAM,gBAAgB,QACjB,IAAI,CAAC,QAAQ,WAAW,EAAE,QAAQ,YAAY,2CAAc,OAAO,EAAE,EACrE,OAAO,CAAC,EAAE,OAAO,MAAO,OAAO,WAAW,eAAe,OAAO,SAAS,QAC1E,OAAO,WAAW,UAAU;AAEhC,UAAM,cAAc,CAAC;AACrB,UAAM,QAAQ,IAAI,cAAc,IAAI,OAAO,EAAE,QAAQ,eAAe,WAAW,GAAG,MAAM;AACpF,UAAI,cAAc,WAAW,aAAa;AACtC,cAAM,SAAS,cAAc;AAC7B,oBAAY,CAAC,IAAI,OAAO,IAAI,CAACC,YAAW;AACpC,cAAI,aAAaA,WACb,cAAcA,QAAO,OAAO,KAC5B,YAAYA,QAAO,OAAO,GAAG;AAE7B,YAAAA,QAAO,QAAQ,iBAAiB;AAAA,cAC5B,cAAc;AAAA,cACd,eAAe;AAAA,cACf,cAAc;AAAA,YAClB;AAAA,UACJ;AAEA,UAAAA,QAAO,iBAAiB;AAAA,YACpB,GAAGA,QAAO;AAAA,YACV,YAAY,CAAC;AAAA,UACjB;AACA,iBAAOA;AAAA,QACX,CAAC;AACD,YAAI,OAAO,QAAQ;AACf,iBAAM,yCAAY,kBAAkB,OAAO,CAAC,EAAE;AAAA,QAClD;AACA,eAAO,yCAAY,aAAa;AAAA,UAC5B,aAAa,CAAC,MAAM;AAAA,QACxB,GAAG,QAAW,QAAW,QAAW;AAAA,UAChC,QAAQ;AAAA,QACZ;AAAA,MACJ,OACK;AAED,eAAM,yCAAY,eAAe,cAAc,QAAQ,QAAW,QAAW,QAAW;AAAA,UACpF,QAAQ;AAAA,QACZ;AACA,eAAO,QAAQ,OAAO,cAAc,MAAM;AAAA,MAC9C;AAAA,IACJ,CAAC,CAAC;AACF,UAAM,SAAS;AAAA,MACX;AAAA,MACA;AAAA,MACA,oBAAoB;AAAA,IACxB;AAIA,WAAO,eAAe,QAAQ,SAAS;AAAA,MACnC,OAAO,cACD,EAAE,QAAQ,2CAAa,IAAI,CAAC,YAAY,QAAQ,OAAO,IACvD;AAAA,MACN,cAAc;AAAA,IAClB,CAAC;AACD,WAAO;AAAA,EACX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,SAAS,UAAU,SAAS,WAAW;AAEzC,QAAI;AACJ,QAAI,MAAM,QAAQ,OAAO,GAAG;AACxB,sBAAgB,EAAE,MAAM,QAAQ;AAAA,IACpC,OACK;AACD,sBAAgB;AAAA,IACpB;AACA,UAAM,eAAe,SAAS,IAAI,CAAC,gBAAgB,YAAY,IAAI,0BAA0B,CAAC;AAC9F,UAAM,CAAC,gBAAgB,WAAW,IAAI,KAAK,6CAA6C,aAAa;AACrG,mBAAe,YAAY,eAAe,aAAa;AACvD,QAAI,CAAC,KAAK,OAAO;AACb,aAAO,KAAK,kBAAkB,cAAc,aAAa,cAAc;AAAA,IAC3E;AACA,UAAM,EAAE,MAAM,IAAI;AAClB,UAAM,eAAe,KAAK,wCAAwC,WAAW;AAC7E,UAAM,EAAE,aAAa,sBAAsB,mBAAmB,IAAI,MAAM,KAAK,gBAAgB;AAAA,MACzF,UAAU;AAAA,MACV;AAAA,MACA;AAAA,MACA,eAAe;AAAA,MACf,gBAAgB;AAAA,IACpB,CAAC;AACD,QAAI,YAAY,CAAC;AACjB,QAAI,qBAAqB,SAAS,GAAG;AACjC,YAAM,UAAU,MAAM,KAAK,kBAAkB,qBAAqB,IAAI,CAAC,MAAM,aAAa,CAAC,CAAC,GAAG,aAAa,gBAAgB,uBAAuB,SAC7I,qBAAqB,IAAI,CAAC,MAAM,yDAAqB,EAAE,IACvD,MAAS;AACf,YAAM,QAAQ,IAAI,QAAQ,YAAY,IAAI,OAAO,YAAY,UAAU;AACnE,cAAM,cAAc,qBAAqB,KAAK;AAC9C,oBAAY,WAAW,IAAI;AAE3B,cAAM,SAAS,eAAc,2BAA2B,aAAa,WAAW,CAAC,EAAE,SAAS;AAC5F,eAAO,MAAM,OAAO,QAAQ,cAAc,UAAU;AAAA,MACxD,CAAC,CAAC;AACF,kBAAY,QAAQ,aAAa,CAAC;AAAA,IACtC;AACA,WAAO,EAAE,aAAa,UAAU;AAAA,EACpC;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,iBAAiB,UAAU;AACvB,WAAO,CAAC;AAAA,EACZ;AAAA,EACA,aAAa;AACT,WAAO;AAAA,EACX;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,YAAY;AACR,WAAO;AAAA,MACH,GAAG,KAAK,iBAAiB;AAAA,MACzB,OAAO,KAAK,SAAS;AAAA,MACrB,QAAQ,KAAK,WAAW;AAAA,IAC5B;AAAA,EACJ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAQA,MAAM,eAAe,cAAc,SAAS,WAAW;AACnD,UAAM,iBAAiB,aAAa,IAAI,CAAC,gBAAgB,YAAY,eAAe,CAAC;AACrF,WAAO,KAAK,SAAS,gBAAgB,SAAS,SAAS;AAAA,EAC3D;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,KAAK,UAAU,SAAS,WAAW;AACrC,UAAM,SAAS,MAAM,KAAK,SAAS,CAAC,SAAS,IAAI,0BAA0B,CAAC,GAAG,SAAS,SAAS;AACjG,UAAM,cAAc,OAAO;AAC3B,WAAO,YAAY,CAAC,EAAE,CAAC,EAAE;AAAA,EAC7B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,WAAW,aAAa,SAAS,WAAW;AAC9C,UAAM,iBAAiB,YAAY,eAAe;AAClD,WAAO,KAAK,KAAK,gBAAgB,SAAS,SAAS;AAAA,EACvD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,gBAAgB,UAAU,SAAS,WAAW;AAChD,WAAO,KAAK,KAAK,UAAU,SAAS,SAAS;AAAA,EACjD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,EAUA,MAAM,QAAQ,MAAM,SAAS,WAAW;AACpC,UAAM,UAAU,IAAI,aAAa,IAAI;AACrC,UAAM,SAAS,MAAM,KAAK,KAAK,CAAC,OAAO,GAAG,SAAS,SAAS;AAC5D,QAAI,OAAO,OAAO,YAAY,UAAU;AACpC,YAAM,IAAI,MAAM,iDAAiD;AAAA,IACrE;AACA,WAAO,OAAO;AAAA,EAClB;AAAA,EACA,qBAAqB,cAAc,QAAQ;AACvC,QAAI,OAAO,KAAK,cAAc,YAAY;AACtC,YAAM,IAAI,MAAM,uEAAuE;AAAA,IAC3F;AACA,QAAI,iCAAQ,QAAQ;AAChB,YAAM,IAAI,MAAM,2DAA2D;AAAA,IAC/E;AAEA,UAAM,SAAS;AACf,UAAM,OAAO,iCAAQ;AACrB,UAAM,cAAc,OAAO,eAAe;AAC1C,UAAM,SAAS,iCAAQ;AACvB,UAAM,aAAa,iCAAQ;AAC3B,QAAI,WAAW,YAAY;AACvB,YAAM,IAAI,MAAM,uFAAuF;AAAA,IAC3G;AACA,QAAI,eAAe,QAAQ;AAC3B,QAAI;AACJ,QAAI,YAAY,MAAM,GAAG;AACrB,cAAQ;AAAA,QACJ;AAAA,UACI,MAAM;AAAA,UACN,UAAU;AAAA,YACN,MAAM;AAAA,YACN;AAAA,YACA,YAAY,gBAAgB,MAAM;AAAA,UACtC;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ,OACK;AACD,UAAI,UAAU,QAAQ;AAClB,uBAAe,OAAO;AAAA,MAC1B;AACA,cAAQ;AAAA,QACJ;AAAA,UACI,MAAM;AAAA,UACN,UAAU;AAAA,YACN,MAAM;AAAA,YACN;AAAA,YACA,YAAY;AAAA,UAChB;AAAA,QACJ;AAAA,MACJ;AAAA,IACJ;AACA,UAAM,MAAM,KAAK,UAAU,KAAK;AAChC,UAAM,eAAe,eAAe,KAAK,CAAC,UAAU;AAChD,UAAI,CAAC,MAAM,cAAc,MAAM,WAAW,WAAW,GAAG;AACpD,cAAM,IAAI,MAAM,sCAAsC;AAAA,MAC1D;AACA,YAAM,WAAW,MAAM,WAAW,KAAK,CAAC,OAAO,GAAG,SAAS,YAAY;AACvE,UAAI,CAAC,UAAU;AACX,cAAM,IAAI,MAAM,gCAAgC,YAAY,GAAG;AAAA,MACnE;AACA,aAAO,SAAS;AAAA,IACpB,CAAC;AACD,QAAI,CAAC,YAAY;AACb,aAAO,IAAI,KAAK,YAAY,EAAE,WAAW;AAAA,QACrC,SAAS;AAAA,MACb,CAAC;AAAA,IACL;AACA,UAAM,eAAe,oBAAoB,OAAO;AAAA;AAAA,MAE5C,QAAQ,CAAC,OAAOC,YAAW,aAAa,OAAO,MAAM,KAAKA,OAAM;AAAA,IACpE,CAAC;AACD,UAAM,aAAa,oBAAoB,OAAO;AAAA,MAC1C,QAAQ,MAAM;AAAA,IAClB,CAAC;AACD,UAAM,qBAAqB,aAAa,cAAc;AAAA,MAClD,WAAW,CAAC,UAAU;AAAA,IAC1B,CAAC;AACD,WAAO,iBAAiB,KAAK;AAAA,MACzB;AAAA,QACI,KAAK;AAAA,MACT;AAAA,MACA;AAAA,IACJ,CAAC,EAAE,WAAW;AAAA,MACV,SAAS;AAAA,IACb,CAAC;AAAA,EACL;AACJ;",
  "names": ["_a", "_b", "result", "config"]
}
